{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "# Install required R packages (if needed)\n",
        "pkgs <- c(\"keras3\", \"jpeg\", \"tfdatasets\")\n",
        "to_install <- pkgs[!vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)]\n",
        "if (length(to_install)) install.packages(to_install)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "library(keras3)\n",
        "py_require(\"keras-hub\")\n",
        "library(tfdatasets, exclude = \"shape\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "digit_size <- 28\n",
        "batch_size <- 32\n",
        "image_size <- 128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "layer_sampler <- new_layer_class(\n",
        "  classname = \"Sampler\",\n",
        "  initialize = function(...) {\n",
        "    super$initialize(...)\n",
        "    self$seed_generator <- random_seed_generator()                              # <1>\n",
        "    self$built <- TRUE\n",
        "  },\n",
        "  call = function(z_mean, z_log_var) {\n",
        "    .[batch_size, z_size] <- op_shape(z_mean)\n",
        "    epsilon <- random_normal(shape = op_shape(z_mean),                          # <2>\n",
        "                             seed = self$seed_generator)                        # <2>\n",
        "    z_mean + (op_exp(0.5 * z_log_var) * epsilon)                                # <3>\n",
        "  }\n",
        ")\n",
        "\n",
        "residual_block <- function(x, width) {                                          # <1>\n",
        "  .[.., n_features] <- op_shape(x)\n",
        "\n",
        "  if (n_features == width) {\n",
        "    residual <- x\n",
        "  } else {\n",
        "    residual <- x |> layer_conv_2d(filters = width, kernel_size = 1)\n",
        "  }\n",
        "\n",
        "  x <- x |>\n",
        "    layer_batch_normalization(center = FALSE, scale = FALSE) |>\n",
        "    layer_conv_2d(width, kernel_size = 3, padding = \"same\",\n",
        "                  activation = \"swish\") |>\n",
        "    layer_conv_2d(width, kernel_size = 3, padding = \"same\")\n",
        "\n",
        "  x + residual\n",
        "}\n",
        "\n",
        "get_model <- function(image_size, widths, block_depth) {\n",
        "  noisy_images <- keras_input(shape = c(image_size, image_size, 3))\n",
        "  noise_rates <- keras_input(shape = c(1, 1, 1))\n",
        "\n",
        "  x <- noisy_images |> layer_conv_2d(filters = widths[1], kernel_size = 1)\n",
        "  n <- noise_rates |>\n",
        "    layer_upsampling_2d(size = image_size, interpolation = \"nearest\")\n",
        "  x <- layer_concatenate(c(x, n))\n",
        "\n",
        "  skips <- list()\n",
        "\n",
        "  for (width in head(widths, -1)) {                                             # <2>\n",
        "    for (i in seq_len(block_depth)) {                                           # <2>\n",
        "      x <- x |> residual_block(width)                                           # <2>\n",
        "      skips <- c(skips, x)\n",
        "    }\n",
        "    x <- x |> layer_average_pooling_2d(pool_size = 2)\n",
        "  }\n",
        "\n",
        "  for (i in seq_len(block_depth)) {                                             # <3>\n",
        "    x <- x |> residual_block(tail(widths, 1))                                   # <3>\n",
        "  }\n",
        "\n",
        "  for (width in rev(head(widths, -1))) {                                        # <4>\n",
        "    x <- x |> layer_upsampling_2d(size = 2, interpolation = \"bilinear\")         # <4>\n",
        "    for (i in seq_len(block_depth)) {                                           # <4>\n",
        "      x <- x |> layer_concatenate(tail(skips, 1)[[1]])                          # <4>\n",
        "      skips <- head(skips, -1)\n",
        "      x <- x |> residual_block(width)\n",
        "    }\n",
        "  }\n",
        "\n",
        "  pred_noise_masks <- x |> layer_conv_2d(                                       # <5>\n",
        "    filters = 3, kernel_size = 1, kernel_initializer = \"zeros\"                  # <5>\n",
        "  )                                                                             # <5>\n",
        "\n",
        "  model <- keras_model(inputs = list(noisy_images, noise_rates),                # <6>\n",
        "                       outputs = pred_noise_masks)                              # <6>\n",
        "  model\n",
        "}\n",
        "\n",
        "diffusion_schedule <- function(diffusion_times, min_signal_rate = 0.02,\n",
        "                               max_signal_rate = 0.95) {\n",
        "  start_angle <- op_arccos(max_signal_rate) |> op_cast(dtype = \"float32\")\n",
        "  end_angle <- op_arccos(min_signal_rate) |> op_cast(dtype = \"float32\")\n",
        "\n",
        "  diffusion_angles <-\n",
        "    start_angle + diffusion_times * (end_angle - start_angle)\n",
        "  signal_rates <- op_cos(diffusion_angles)\n",
        "  noise_rates <- op_sin(diffusion_angles)\n",
        "  list(noise_rates = noise_rates, signal_rates = signal_rates)\n",
        "}\n",
        "\n",
        "callback_visualization <- new_callback_class(\n",
        "  classname = \"VisualizationCallback\",\n",
        "  initialize = function(diffusion_steps = 20, num_rows = 3, num_cols = 6) {\n",
        "    self$diffusion_steps <- diffusion_steps\n",
        "    self$num_rows <- num_rows\n",
        "    self$num_cols <- num_cols\n",
        "  },\n",
        "\n",
        "  on_epoch_end = function(epoch = NULL, logs = NULL) {\n",
        "    generated_images <- self$model$generate(\n",
        "      num_images = self$num_rows * self$num_cols,\n",
        "      diffusion_steps = self$diffusion_steps\n",
        "    ) |> as.array()\n",
        "\n",
        "    par(mfrow = c(self$num_rows, self$num_cols),\n",
        "        mar = c(0, 0, 0, 0))\n",
        "\n",
        "    for (i in seq_len(self$num_rows * self$num_cols))\n",
        "      plot(as.raster(generated_images[i, , , ], max = 255))\n",
        "\n",
        "  }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "# Split marker for notebook/code extraction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "rm(list = ls()); gc(); import(\"gc\")$collect(); gc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Creating a Stable Diffusion text-to-image model\n",
        "library(keras3)\n",
        "py_require(\"keras-hub\")\n",
        "keras_hub <- import(\"keras_hub\")\n",
        "\n",
        ".[height, width] <- c(512, 512)\n",
        "task <- keras_hub$models$TextToImage$from_preset(\n",
        "  \"stable_diffusion_3_medium\",\n",
        "  image_shape = shape(height, width, 3),\n",
        "  dtype = \"float16\"                                                             # <1>\n",
        ")\n",
        "prompt <- \"A NASA astronaut riding an origami elephant in New York City\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "image <- task$generate(prompt)\n",
        "par(mar = c(0, 0, 0, 0))\n",
        "plot(as.raster(image, max = max(image)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "image <- task$generate(list(\n",
        "  prompts = prompt,\n",
        "  negative_prompts = \"blue color\"\n",
        "))\n",
        "par(mar = c(0, 0, 0, 0))\n",
        "plot(as.raster(image, max = max(image)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "par(mfrow = c(1, 5), mar = c(0, 0, 0, 0))\n",
        "for (num_steps in c(5, 10, 15, 20, 25)) {\n",
        "  image <- task$generate(prompt, num_steps = num_steps)\n",
        "  plot(as.raster(image, max = max(image)))\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| output: false\n",
        "#| eval: true\n",
        "#| lst-cap: \"Breaking down the `generate()` function\"\n",
        "get_text_embeddings <- function(prompt) {\n",
        "  token_ids <- task$preprocessor$generate_preprocess(list(prompt))\n",
        "  negative_token_ids <- task$preprocessor$generate_preprocess(list(\"\"))         # <1>\n",
        "  task$backbone$encode_text_step(token_ids, negative_token_ids)\n",
        "}\n",
        "\n",
        "denoise_with_text_embeddings <- function(\n",
        "  embeddings,\n",
        "  num_steps = 28L,\n",
        "  guidance_scale = 7\n",
        ") {\n",
        "  latents <- random_normal(c(1, height %/% 8, width %/% 8, 16))                 # <2>\n",
        "  for (step in seq_len(num_steps)) {\n",
        "    latents <- latents |>\n",
        "      task$backbone$denoise_step(\n",
        "        embeddings, step, num_steps, guidance_scale\n",
        "      )\n",
        "  }\n",
        "  task$backbone$decode_step(latents)@r[1]\n",
        "}\n",
        "\n",
        "\n",
        "scale_output <- function(x) {\n",
        "  op_clip((x + 1) / 2, 0, 1)                                                    # <3>\n",
        "}\n",
        "\n",
        "embeddings <- get_text_embeddings(prompt)\n",
        "image <- denoise_with_text_embeddings(embeddings)\n",
        "image <- scale_output(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# par(mar = c(0,0,0,0))\n",
        "# plot(as.raster(as.array(image)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "str(embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Function to interpolate text embeddings\n",
        "slerp <- function(t, v1, v2) {\n",
        "  .[v1, v2] <- list(v1, v2) |> lapply(op_cast, \"float32\")\n",
        "  v1_norm  <- op_norm(op_ravel(v1))\n",
        "  v2_norm  <- op_norm(op_ravel(v2))\n",
        "  dot <- op_sum(v1 * v2 / (v1_norm * v2_norm))\n",
        "  theta_0 <- op_arccos(dot)\n",
        "  sin_theta_0 <- op_sin(theta_0)\n",
        "  theta_t <- theta_0 * t\n",
        "  sin_theta_t <- op_sin(theta_t)\n",
        "  s0 <- op_sin(theta_0 - theta_t) / sin_theta_0\n",
        "  s1 <- sin_theta_t / sin_theta_0\n",
        "  s0 * v1 + s1 * v2\n",
        "}\n",
        "\n",
        "interpolate_text_embeddings <- function(e1, e2, start=0, end=1, num=10) {\n",
        "  lapply(seq(start, end, length.out = num), \\(t) {\n",
        "    list(\n",
        "      slerp(t, e1[[1]], e2[[1]]),\n",
        "      e1[[2]],                                                                  # <1>\n",
        "      slerp(t, e1[[3]], e2[[3]]),\n",
        "      e1[[4]]                                                                   # <1>\n",
        "    )\n",
        "  })\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "par(mar = c(0,0,0,0))\n",
        "prompt1 <- \"A friendly dog looking up in a field of flowers\"\n",
        "prompt2 <- \"A horrifying, tentacled creature hovering over a field of flowers\"\n",
        "e1 <- get_text_embeddings(prompt1)\n",
        "e2 <- get_text_embeddings(prompt2)\n",
        "\n",
        "for (et in interpolate_text_embeddings(e1, e2, start=0.5, end=0.6, num=9)) {    # <1>\n",
        "  image <- denoise_with_text_embeddings(et)\n",
        "  plot(as.raster(as.array(scale_output(image))))\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R",
      "version": "4.5.2",
      "mimetype": "text/x-r-source",
      "codemirror_mode": {
        "name": "r",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
