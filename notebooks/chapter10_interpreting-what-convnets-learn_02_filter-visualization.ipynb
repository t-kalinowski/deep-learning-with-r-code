{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "# Install required R packages (if needed)\n",
        "pkgs <- c(\"keras3\", \"viridis\", \"withr\")\n",
        "to_install <- pkgs[!vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)]\n",
        "if (length(to_install)) install.packages(to_install)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "library(keras3)\n",
        "use_backend(\"tensorflow\")\n",
        "reticulate::py_require(\"keras-hub\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "get_img_array <- function(img_path, target_size) {\n",
        "  image <- img_path |>\n",
        "    image_load(target_size = target_size) |>                                    # <2>\n",
        "    image_to_array()                                                            # <3>\n",
        "  dim(image) <- c(1, dim(image))                                                # <4>\n",
        "  image\n",
        "}\n",
        "\n",
        "display_image <- function(x, ..., max = 255L, margin = 0) {\n",
        "  par(mar = rep(margin, 4))\n",
        "\n",
        "  x |> as.array() |> drop() |>\n",
        "    as.raster(max = max) |>\n",
        "    plot(..., interpolate = FALSE)\n",
        "}\n",
        "\n",
        "plot_activations <- function(x, ...) {\n",
        "  withr::local_par(list(mar = c(0,0,0,0)))\n",
        "\n",
        "  x <- drop(as.array(x))\n",
        "  if (sum(x) == 0)\n",
        "    return(plot(as.raster(\"gray\")))\n",
        "\n",
        "  rotate <- function(x) t(apply(x, 2, rev))\n",
        "  graphics::image(\n",
        "    rotate(x), asp = 1, axes = FALSE, useRaster = TRUE,\n",
        "    col = viridis::viridis(256), ...\n",
        "  )\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "# Split marker for notebook/code extraction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "py_require(\"keras-hub\")\n",
        "keras_hub <- import(\"keras_hub\")\n",
        "\n",
        "model <- keras_hub$models$Backbone$from_preset(                                 # <1>\n",
        "  \"xception_41_imagenet\"                                                        # <1>\n",
        ")                                                                               # <1>\n",
        "preprocessor <- keras_hub$layers$ImageConverter$from_preset(                    # <2>\n",
        "  \"xception_41_imagenet\",                                                       # <2>\n",
        "  image_size = shape(180, 180)                                                  # <2>\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hide\n",
        "#| lst-cap: Printing the names of Xception convolutional layers\n",
        "unlist(lapply(model$layers, \\(layer) {\n",
        "  if (inherits(layer, keras$layers$Conv2D) ||\n",
        "      inherits(layer, keras$layers$SeparableConv2D))\n",
        "    layer$name\n",
        "}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Feature extractor model returning a specific output\n",
        "layer_name <- \"block3_sepconv1\"                                                 # <1>\n",
        "layer <- get_layer(model, name = layer_name)                                    # <2>\n",
        "feature_extractor <-\n",
        "  keras_model(inputs = model$input,                                             # <3>\n",
        "              outputs = layer$output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "activation <- img |> preprocessor() |> feature_extractor()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "compute_loss <- function(image, filter_index) {                                 # <1>\n",
        "  activation <- feature_extractor(image)\n",
        "  filter_activation <- activation@r[, 3:-3, 3:-3, filter_index]                 # <2>\n",
        "  op_mean(filter_activation)                                                    # <3>\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# predict <- function(model, x, batch_size = 32) {\n",
        "#   y <- list()\n",
        "#   for (x_batch in split_into_batches(x, batch_size)) {\n",
        "#     y_batch <- as.array(model(x_batch))\n",
        "#     y[[length(y)+1]] <- y_batch\n",
        "#   }\n",
        "#   unsplit_batches(y)\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Stochastic gradient ascent in TensorFlow\n",
        "if (keras3::config_backend() == \"tensorflow\") {\n",
        "  library(tensorflow, exclude = c(\"set_random_seed\", \"shape\"))\n",
        "\n",
        "  gradient_ascent_step <- tf_function(\\(image, filter_index, learning_rate) {\n",
        "    with(tf$GradientTape() %as% tape, {\n",
        "      tape$watch(image)                                                           # <1>\n",
        "      loss <- compute_loss(image, filter_index)                                   # <2>\n",
        "    })\n",
        "    grads <- tape$gradient(loss, image)                                           # <3>\n",
        "    grads <- op_normalize(grads)                                                  # <4>\n",
        "    image + (learning_rate * grads)                                               # <5>\n",
        "  })\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "if (keras3::config_backend() == \"torch\") {\n",
        "  torch <- import(\"torch\")\n",
        "  gradient_ascent_step <- function(image, filter_index, learning_rate) {\n",
        "    image <- image$clone()$detach()$requires_grad_(TRUE)                          # <1>\n",
        "    loss <- compute_loss(image, filter_index)\n",
        "    loss$backward()\n",
        "    grads <- image$grad\n",
        "    grads <- op_normalize(grads)\n",
        "    image + (learning_rate * grads)\n",
        "  }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "if (keras3::config_backend() == \"jax\") {\n",
        "  jax <- import(\"jax\")\n",
        "\n",
        "  grad_fn <- jax$grad(compute_loss)\n",
        "\n",
        "  gradient_ascent_step <- jax$jit(\\(image, filter_index, learning_rate) {\n",
        "    grads <- grad_fn(image, filter_index)\n",
        "    grads <- op_normalize(grads)\n",
        "    image + (learning_rate * grads)\n",
        "  })\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Function to generate filter visualizations\n",
        "img_height <- img_width <- 200\n",
        "\n",
        "generate_filter_pattern <- function(filter_index) {\n",
        "  iterations <- 30                                                              # <1>\n",
        "  learning_rate <- 10                                                           # <2>\n",
        "  image <- random_uniform(                                                      # <3>\n",
        "    minval = 0.4, maxval = 0.6,                                                 # <3>\n",
        "    shape = shape(1, img_width, img_height, 3)                                  # <3>\n",
        "  )\n",
        "\n",
        "  for (i in seq(iterations))                                                    # <4>\n",
        "    image <- gradient_ascent_step(image, filter_index, learning_rate)           # <4>\n",
        "\n",
        "  image\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Utility function to convert a tensor into a valid image\n",
        "deprocess_image <- function(image, crop = TRUE) {\n",
        "  image <- op_squeeze(image, axis = 1)                                          # <1>\n",
        "  image <- image - op_mean(image)                                               # <2>\n",
        "  image <- image / op_std(image)                                                # <2>\n",
        "  image <- (image * 64) + 128                                                   # <2>\n",
        "  image <- op_clip(image, 0, 255)                                               # <2>\n",
        "  if (crop) {\n",
        "    image <- image@r[26:-26, 26:-26, ]                                          # <3>\n",
        "  }\n",
        "  op_cast(image, \"uint8\")\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hide\n",
        "#| fig-cap: \"Pattern that the third channel in layer `block3_sepconv1` responds to maximally\"\n",
        "generate_filter_pattern(filter_index = 3L) |>\n",
        "  deprocess_image() |>\n",
        "  display_image()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Generating a grid of all filter response patterns in a layer\n",
        "#| results: hide\n",
        "par(mfrow = c(8, 8))\n",
        "for (i in seq_len(64)) {\n",
        "  generate_filter_pattern(filter_index = i) |>\n",
        "    deprocess_image() |>\n",
        "    display_image(margin = .1)\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R",
      "version": "4.5.2",
      "mimetype": "text/x-r-source",
      "codemirror_mode": {
        "name": "r",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
