{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "# Install required R packages (if needed)\n",
        "pkgs <- c(\"keras3\", \"qpdf\")\n",
        "to_install <- pkgs[!vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)]\n",
        "if (length(to_install)) install.packages(to_install)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "Sys.setenv(\"KERAS_BACKEND\" = \"jax\")\n",
        "library(keras3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"The `Sequential` class\"\n",
        "library(keras3)\n",
        "\n",
        "model <- keras_model_sequential() |>\n",
        "  layer_dense(64, activation = \"relu\") |>\n",
        "  layer_dense(10, activation = \"softmax\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"Incrementally building a `Sequential` model\"\n",
        "model <- keras_model_sequential()\n",
        "model |> layer_dense(64, activation = \"relu\")\n",
        "model |> layer_dense(10, activation = \"softmax\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"Model that isn't built and has no weights\"\n",
        "model$weights                                                                   # <1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Calling a model for the first time to build it\n",
        "model$build(input_shape = shape(NA, 3))                                         # <1>\n",
        "str(model$weights)                                                              # <2>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: The summary method\n",
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"Naming models and layers with the `name` argument\"\n",
        "model <- keras_model_sequential(name = \"my_example_model\")\n",
        "model |> layer_dense(64, activation = \"relu\", name = \"my_first_layer\")\n",
        "model |> layer_dense(10, activation = \"softmax\", name = \"my_last_layer\")\n",
        "model$build(shape(NA, 3))\n",
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Specifying the input shape of a model in advance\n",
        "model <- keras_model_sequential(input_shape = c(3))                             # <1>\n",
        "model |> layer_dense(64, activation = \"relu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model |> layer_dense(10, activation = \"softmax\")\n",
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"A simple Functional model with two `Dense` layers\"\n",
        "inputs <- keras_input(shape = c(3), name = \"my_input\")\n",
        "features <- inputs |> layer_dense(64, activation = \"relu\")\n",
        "outputs <- features |> layer_dense(10, activation = \"softmax\")\n",
        "model <- keras_model(inputs = inputs, outputs = outputs,\n",
        "                     name = \"my_functional_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "inputs <- keras_input(shape = c(3), name = \"my_input\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "op_shape(inputs)                                                                # <1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "op_dtype(inputs)                                                                # <1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "features <- inputs |> layer_dense(64, activation = \"relu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "op_shape(features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "outputs <- features |> layer_dense(10, activation = \"softmax\")\n",
        "model <- keras_model(inputs = inputs, outputs = outputs,\n",
        "                     name = \"my_functional_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"A multi-input, multi-output Functional model\"\n",
        "vocabulary_size <- 10000\n",
        "num_tags <- 100\n",
        "num_departments <- 4\n",
        "\n",
        "title <- keras_input(c(vocabulary_size), name = \"title\")                        # <1>\n",
        "text_body <- keras_input(c(vocabulary_size), name = \"text_body\")                # <1>\n",
        "tags <- keras_input(c(num_tags), name = \"tags\")                                 # <1>\n",
        "\n",
        "features <-\n",
        "  layer_concatenate(c(title, text_body, tags)) |>                               # <2>\n",
        "  layer_dense(64, activation = \"relu\", name = \"dense_features\")                 # <3>\n",
        "\n",
        "priority <- features |>                                                         # <4>\n",
        "  layer_dense(1, activation = \"sigmoid\", name = \"priority\")\n",
        "\n",
        "department <- features |>                                                       # <4>\n",
        "  layer_dense(num_departments, activation = \"softmax\", name = \"department\")\n",
        "\n",
        "model <- keras_model(                                                           # <5>\n",
        "  inputs = c(title, text_body, tags),                                           # <5>\n",
        "  outputs = c(priority, department)                                             # <5>\n",
        ")                                                                               # <5>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hide\n",
        "#| message: false\n",
        "#| output: false\n",
        "#| lst-cap: Training a model by providing lists of input and target arrays\n",
        "num_samples <- 1280\n",
        "\n",
        "random_uniform_array <- function(dim) {\n",
        "  array(runif(prod(dim)), dim)\n",
        "}\n",
        "\n",
        "random_integer_array <- function(dim, minval = 0L, maxval = 1L) {\n",
        "  array(sample(minval:maxval, prod(dim), replace = TRUE), dim)\n",
        "}\n",
        "\n",
        "title_data     <- random_integer_array(c(num_samples, vocabulary_size))         # <1>\n",
        "text_body_data <- random_integer_array(c(num_samples, vocabulary_size))         # <1>\n",
        "tags_data      <- random_integer_array(c(num_samples, num_tags))                # <1>\n",
        "\n",
        "priority_data <- random_uniform_array(c(num_samples, 1))                        # <2>\n",
        "department_data <- random_integer_array(                                        # <2>\n",
        "  dim = c(num_samples, 1),                                                      # <2>\n",
        "  maxval = num_departments - 1                                                  # <2>\n",
        ")                                                                               # <2>\n",
        "\n",
        "model |> compile(\n",
        "  optimizer = \"adam\",\n",
        "  loss = c(\"mean_squared_error\", \"sparse_categorical_crossentropy\"),\n",
        "  metrics = list(c(\"mean_absolute_error\"), c(\"accuracy\"))\n",
        ")\n",
        "\n",
        "model |> fit(\n",
        "  x = list(title_data, text_body_data, tags_data),\n",
        "  y = list(priority_data, department_data),\n",
        "  epochs = 1\n",
        ")\n",
        "\n",
        "model |> evaluate(\n",
        "  x = list(title_data, text_body_data, tags_data),\n",
        "  y = list(priority_data, department_data)\n",
        ")\n",
        "\n",
        ".[priority_preds, department_preds] <- model |> predict(\n",
        "  list(title_data, text_body_data, tags_data)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| output: false\n",
        "#| lst-cap: Training a model by providing dicts of input and target arrays\n",
        "model |> compile(\n",
        "  optimizer = \"adam\",\n",
        "  loss = list(\n",
        "    priority = \"mean_squared_error\",\n",
        "    department = \"sparse_categorical_crossentropy\"\n",
        "  ),\n",
        "  metrics = list(\n",
        "    priority = c(\"mean_absolute_error\"),\n",
        "    department = c(\"accuracy\")\n",
        "  )\n",
        ")\n",
        "\n",
        "model |> fit(\n",
        "  x = list(title = title_data, text_body = text_body_data, tags = tags_data),\n",
        "  y = list(priority = priority_data, department = department_data),\n",
        "  epochs = 1\n",
        ")\n",
        "\n",
        "model |> evaluate(\n",
        "  x = list(title = title_data, text_body = text_body_data, tags = tags_data),\n",
        "  y = list(priority = priority_data, department = department_data)\n",
        ")\n",
        "\n",
        ".[priority_preds, department_preds] <- model |> predict(\n",
        "  list(title = title_data, text_body = text_body_data, tags = tags_data)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: true\n",
        "#| fig-cap: \"Plot generated by `plot()` on our ticket classifier model\"\n",
        "plot(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: true\n",
        "#| fig-cap: Model plot with shape information added\n",
        "plot(model, show_shapes = TRUE, show_layer_names = TRUE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Retrieving inputs or outputs of a layer in a Functional model\n",
        "model$layers |> str()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model$layers[[4]]$input |> str()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model$layers[[4]]$output |> str()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Creating a new model by reusing intermediate layer outputs\n",
        "features <- model$layers[[5]]$output                                            # <1>\n",
        "difficulty <- features |>\n",
        "  layer_dense(3, activation = \"softmax\", name = \"difficulty\")\n",
        "\n",
        "new_model <- keras_model(\n",
        "  inputs = list(title, text_body, tags),\n",
        "  outputs = list(priority, department, difficulty)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: true\n",
        "#| fig-cap: Updated ticket classifier model with added difficulty output\n",
        "plot(new_model, show_shapes = TRUE, show_layer_names = TRUE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: A simple subclassed model\n",
        "CustomerTicketModel <- new_model_class(\n",
        "  classname = \"CustomerTicketModel\",\n",
        "\n",
        "  initialize = function(num_departments) {\n",
        "    super$initialize()                                                          # <1>\n",
        "    self$concat_layer <- layer_concatenate()                                    # <2>\n",
        "    self$mixing_layer <- layer_dense(, 64, activation = \"relu\")                 # <2>\n",
        "    self$priority_scorer <- layer_dense(, 1, activation = \"sigmoid\")            # <2>\n",
        "    self$department_classifier <- layer_dense(, num_departments,                # <2>\n",
        "                                              activation = \"softmax\")           # <2>\n",
        "  },\n",
        "\n",
        "  call = function(inputs) {                                                     # <3>\n",
        "    .[title = title, text_body = text_body, tags = tags] <- inputs\n",
        "\n",
        "    features <- list(title, text_body, tags) |>\n",
        "      self$concat_layer() |>\n",
        "      self$mixing_layer()\n",
        "    priority <- features |> self$priority_scorer()\n",
        "    department <- features |> self$department_classifier()\n",
        "    list(priority, department)\n",
        "  }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model <- CustomerTicketModel(num_departments = 4)\n",
        ".[priority, department] <- model(list(\n",
        "  title = title_data,\n",
        "  text_body = text_body_data,\n",
        "  tags = tags_data\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hide\n",
        "#| output: false\n",
        "model |> compile(\n",
        "  optimizer = \"adam\",\n",
        "  loss = c(\"mean_squared_error\", \"sparse_categorical_crossentropy\"),            # <1>\n",
        "  metrics = c(\"mean_absolute_error\", \"accuracy\")                                # <1>\n",
        ")\n",
        "model |> fit(\n",
        "  x = list(title = title_data,                                                  # <2>\n",
        "           text_body = text_body_data,                                          # <2>\n",
        "           tags = tags_data),                                                   # <2>\n",
        "  y = list(priority_data, department_data),                                     # <2>\n",
        "  epochs = 1\n",
        ")\n",
        "model |> evaluate(\n",
        "  x = list(title = title_data,\n",
        "           text_body = text_body_data,\n",
        "           tags = tags_data),\n",
        "  y = list(priority_data, department_data)\n",
        ")\n",
        ".[priority_preds, department_preds] <- model |> predict(\n",
        "  list(title = title_data,\n",
        "       text_body = text_body_data,\n",
        "       tags = tags_data)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Creating a Functional model that includes a subclassed model\n",
        "Classifier <- new_model_class(\n",
        "  classname = \"Classifier\",\n",
        "\n",
        "  initialize = function(num_classes = 2) {\n",
        "    super$initialize()\n",
        "    if (num_classes == 2) {\n",
        "      num_units <- 1\n",
        "      activation <- \"sigmoid\"\n",
        "    } else {\n",
        "      num_units <- num_classes\n",
        "      activation <- \"softmax\"\n",
        "    }\n",
        "    self$dense <- layer_dense(, num_units, activation = activation)\n",
        "  },\n",
        "\n",
        "  call = function(inputs) {\n",
        "    self$dense(inputs)\n",
        "  }\n",
        ")\n",
        "\n",
        "classifier <- Classifier(num_classes = 10)\n",
        "\n",
        "inputs <- keras_input(shape = c(3))\n",
        "outputs <- inputs |>\n",
        "  layer_dense(64, activation = \"relu\") |>\n",
        "  classifier()\n",
        "model <- keras_model(inputs = inputs, outputs = outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Creating a subclassed model that includes a Functional model\n",
        "inputs <- keras_input(shape = c(64))\n",
        "outputs <- inputs |> layer_dense(1, activation = \"sigmoid\")\n",
        "binary_classifier <- keras_model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "MyModel <- new_model_class(\n",
        "  classname = \"MyModel\",\n",
        "\n",
        "  initialize = function(num_classes = 2) {\n",
        "    super$initialize()\n",
        "    self$dense <- layer_dense(units = 64, activation = \"relu\")\n",
        "    self$classifier <- binary_classifier\n",
        "  },\n",
        "\n",
        "  call = function(inputs) {\n",
        "    inputs |>\n",
        "      self$dense() |>\n",
        "      self$classifier()\n",
        "  }\n",
        ")\n",
        "\n",
        "model <- MyModel()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: false\n",
        "#| lst-cap: \"Standard workflow: `compile()` / `fit()` / `evaluate()` / `predict()`\"\n",
        "get_mnist_model <- function() {                                                 # <1>\n",
        "  inputs <- keras_input(shape = c(28 * 28))\n",
        "  outputs <- inputs |>\n",
        "    layer_dense(512, activation = \"relu\") |>\n",
        "    layer_dropout(0.5) |>\n",
        "    layer_dense(10, activation = \"softmax\")\n",
        "  keras_model(inputs, outputs)\n",
        "}\n",
        "\n",
        ".[.[images, labels], .[test_images, test_labels]] <- dataset_mnist()            # <2>\n",
        "images <- array_reshape(images, c(60000, 28 * 28)) / 255\n",
        "test_images <- array_reshape(test_images, c(10000, 28 * 28)) / 255\n",
        "train_images <- images[10001:60000, ]\n",
        "val_images <- images[1:10000, ]\n",
        "train_labels <- labels[10001:60000]\n",
        "val_labels <- labels[1:10000]\n",
        "\n",
        "model <- get_mnist_model()                                                      # <3>\n",
        "model |> compile(                                                               # <3>\n",
        "  optimizer = \"adam\",                                                           # <3>\n",
        "  loss = \"sparse_categorical_crossentropy\",                                     # <3>\n",
        "  metrics = \"accuracy\"                                                          # <3>\n",
        ")\n",
        "model |> fit(                                                                   # <4>\n",
        "  train_images, train_labels,                                                   # <4>\n",
        "  epochs = 3,                                                                   # <4>\n",
        "  validation_data = list(val_images, val_labels)                                # <4>\n",
        ")\n",
        "test_metrics <- model |> evaluate(test_images, test_labels)                     # <5>\n",
        "predictions <- model |> predict(test_images)                                    # <6>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"Implementing a custom metric by subclassing the `Metric` class\"\n",
        "metric_sparse_root_mean_squared_error <- new_metric_class(                      # <1>\n",
        "  classname = \"SparseRootMeanSquaredError\",                                     # <1>\n",
        "\n",
        "  initialize = function(name = \"rmse\", ...) {                                   # <2>\n",
        "    super$initialize(name = name, ...)                                          # <2>\n",
        "    self$sum_sq_error <- self$add_weight(                                       # <2>\n",
        "      name = \"sum_sq_error\", initializer = \"zeros\"                              # <2>\n",
        "    )                                                                           # <2>\n",
        "    self$total_samples <- self$add_weight(                                      # <2>\n",
        "      name = \"total_samples\", initializer = \"zeros\"                             # <2>\n",
        "    )                                                                           # <2>\n",
        "  },                                                                            # <2>\n",
        "\n",
        "  update_state = function(y_true, y_pred, sample_weight = NULL) {               # <3>\n",
        "    .[num_samples, num_classes] <- op_shape(y_pred)                             # <3>\n",
        "    y_true <- op_one_hot(                                                       # <3>\n",
        "      y_true,                                                                   # <3>\n",
        "      zero_indexed = TRUE,                                                      # <3>\n",
        "      num_classes = num_classes                                                 # <3>\n",
        "    )                                                                           # <3>\n",
        "    sse <- op_sum(op_square(y_true - y_pred))                                   # <3>\n",
        "    self$sum_sq_error$assign_add(sse)                                           # <3>\n",
        "    self$total_samples$assign_add(num_samples)                                  # <3>\n",
        "  },                                                                            # <3>\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "  result = function() {\n",
        "    op_sqrt(op_divide_no_nan(\n",
        "      self$sum_sq_error,\n",
        "      self$total_samples\n",
        "    ))\n",
        "  },\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "  reset_state = function() {\n",
        "    self$sum_sq_error$assign(0)\n",
        "    self$total_samples$assign(0)\n",
        "  }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hold\n",
        "model <- get_mnist_model()\n",
        "model |> compile(\n",
        "  optimizer = \"adam\",\n",
        "  loss = \"sparse_categorical_crossentropy\",\n",
        "  metrics = list(\"accuracy\", metric_sparse_root_mean_squared_error())\n",
        ")\n",
        "model |> fit(\n",
        "  train_images, train_labels,\n",
        "  epochs = 3,\n",
        "  validation_data = list(val_images, val_labels)\n",
        ")\n",
        "test_metrics <- model |> evaluate(test_images, test_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# callback_model_checkpoint()\n",
        "# callback_early_stopping()\n",
        "# callback_learning_rate_scheduler()\n",
        "# callback_reduce_lr_on_plateau()\n",
        "# callback_csv_logger()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"Using the `callbacks` argument in the `fit()` method\"\n",
        "callbacks_list <- list(                                                         # <1>\n",
        "  callback_early_stopping(                                                      # <2>\n",
        "    monitor = \"val_accuracy\",                                                   # <3>\n",
        "    patience = 1                                                                # <4>\n",
        "  ),\n",
        "  callback_model_checkpoint(                                                    # <5>\n",
        "    filepath = \"checkpoint_path.keras\",                                         # <6>\n",
        "    monitor = \"val_loss\",                                                       # <7>\n",
        "    save_best_only = TRUE                                                       # <7>\n",
        "  )\n",
        ")\n",
        "\n",
        "model <- get_mnist_model()\n",
        "model |> compile(\n",
        "  optimizer = \"adam\",\n",
        "  loss = \"sparse_categorical_crossentropy\",\n",
        "  metrics = \"accuracy\"                                                          # <8>\n",
        ")\n",
        "model |> fit(                                                                   # <9>\n",
        "  train_images, train_labels,                                                   # <9>\n",
        "  epochs = 10,                                                                  # <9>\n",
        "  callbacks = callbacks_list,                                                   # <9>\n",
        "  validation_data = list(val_images, val_labels)                                # <9>\n",
        ")                                                                               # <9>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model <- load_model(\"checkpoint_path.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# on_epoch_begin(epoch, logs)                                                     # <1>\n",
        "# on_epoch_end(epoch, logs)                                                       # <2>\n",
        "# on_batch_begin(batch, logs)                                                     # <3>\n",
        "# on_batch_end(batch, logs)                                                       # <4>\n",
        "# on_train_begin(logs)                                                            # <5>\n",
        "# on_train_end(logs)                                                              # <6>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"Creating a custom callback by subclassing the `Callback` class\"\n",
        "callback_plot_per_batch_loss_history <- new_callback_class(\n",
        "  classname = \"PlotPerBatchLossHistory\",\n",
        "\n",
        "  initialize = function(file = \"training_loss.pdf\") {\n",
        "    private$outfile <- file\n",
        "  },\n",
        "\n",
        "  on_train_begin = function(logs = NULL) {\n",
        "    private$plots_dir <- tempfile()\n",
        "    dir.create(private$plots_dir)\n",
        "    private$per_batch_losses <-\n",
        "      reticulate::py_eval(\"[]\", convert = FALSE)                                # <1>\n",
        "  },\n",
        "\n",
        "  on_epoch_begin = function(epoch, logs = NULL) {\n",
        "    private$per_batch_losses$clear()\n",
        "  },\n",
        "\n",
        "  on_batch_end = function(batch, logs = NULL) {\n",
        "    private$per_batch_losses$append(logs$loss)\n",
        "  },\n",
        "\n",
        "  on_epoch_end = function(epoch, logs = NULL) {\n",
        "    losses <- as.numeric(reticulate::py_to_r(private$per_batch_losses))\n",
        "\n",
        "    filename <- sprintf(\"epoch_%04i.pdf\", epoch)\n",
        "    filepath <- file.path(private$plots_dir, filename)\n",
        "\n",
        "    pdf(filepath, width = 7, height = 5)\n",
        "    on.exit(dev.off())\n",
        "\n",
        "    plot(losses, type = \"o\",\n",
        "         ylim = c(0, max(losses)),\n",
        "         panel.first = grid(),\n",
        "         main = sprintf(\"Training Loss for Each Batch\\n(Epoch %i)\", epoch),\n",
        "         xlab = \"Batch\", ylab = \"Loss\")\n",
        "  },\n",
        "\n",
        "  on_train_end = function(logs) {\n",
        "    private$per_batch_losses <- NULL\n",
        "    plots <- sort(list.files(private$plots_dir, full.names = TRUE))\n",
        "    qpdf::pdf_combine(plots, private$outfile)\n",
        "    unlink(private$plots_dir, recursive = TRUE)\n",
        "  }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model <- get_mnist_model()\n",
        "model |> compile(\n",
        "  optimizer = \"adam\",\n",
        "  loss = \"sparse_categorical_crossentropy\",\n",
        "  metrics = \"accuracy\"\n",
        ")\n",
        "model |> fit(\n",
        "  train_images, train_labels,\n",
        "  epochs = 10,\n",
        "  callbacks = list(callback_plot_per_batch_loss_history()),\n",
        "  validation_data = list(val_images, val_labels)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: The output of our custom history plotting callback\n",
        "if (requireNamespace(\"pdftools\", quietly = TRUE)) {\n",
        "    page <- pdftools::pdf_render_page(\"training_loss.pdf\", dpi = 300)\n",
        "    par(mar = c(0,0,0,0))\n",
        "    plot(as.raster(aperm(unclass(page))))\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model <- get_mnist_model()\n",
        "model |> compile(\n",
        "  optimizer = \"adam\",\n",
        "  loss = \"sparse_categorical_crossentropy\",\n",
        "  metrics = \"accuracy\"\n",
        ")\n",
        "\n",
        "model |> fit(\n",
        "  train_images, train_labels,\n",
        "  epochs = 10,\n",
        "  validation_data = list(val_images, val_labels),\n",
        "  callbacks = c(\n",
        "    callback_tensorboard(\n",
        "      log_dir = \"./full_path_to_your_log_dir\"\n",
        "    )\n",
        "  )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# # Load TensorBoard in R\n",
        "# tensorboard(log_dir = \"./full_path_to_your_log_dir\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "train_step <- function(inputs, targets) {\n",
        "  predictions <-  model(inputs, training = TRUE)                                # <1>\n",
        "  loss <- loss_fn(targets, predictions)                                         # <2>\n",
        "  gradients <- get_gradients_of(loss, wrt = model$trainable_weights)            # <3>\n",
        "  optimizer$apply(gradients, model$trainable_weights)                           # <4>\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "metric <- metric_sparse_categorical_accuracy()\n",
        "targets <- op_array(c(0, 1, 2), dtype = \"int32\")\n",
        "predictions <- op_array(rbind(c(1, 0, 0), c(0, 1, 0), c(0, 0, 1)))\n",
        "metric$update_state(targets, predictions)\n",
        "current_result <- metric$result()\n",
        "cat(sprintf(\"result: %.2f\\n\", current_result))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "mean_tracker <- metric_mean()\n",
        "for(value in 0:4) {\n",
        "  value <- op_array(value)\n",
        "  mean_tracker$update_state(value)\n",
        "}\n",
        "cat(sprintf(\"Mean of values: %.2f\\n\", mean_tracker$result()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "metric <- metric_sparse_categorical_accuracy()\n",
        "targets <- op_array(c(0, 1, 2), dtype = \"int32\")\n",
        "predictions <-  op_array(rbind(c(1, 0, 0), c(0, 1, 0), c(0, 0, 1)))\n",
        "\n",
        "metric_variables <- metric$variables                                            # <1>\n",
        "metric_variables <- metric$stateless_update_state(                              # <2>\n",
        "  metric_variables, targets, predictions                                        # <2>\n",
        ")                                                                               # <2>\n",
        "current_result <- metric$stateless_result(metric_variables)                     # <3>\n",
        "cat(sprintf(\"result: %.2f\\n\", current_result))\n",
        "\n",
        "metric_variables <- metric$stateless_reset_state()                              # <4>\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R",
      "version": "4.5.2",
      "mimetype": "text/x-r-source",
      "codemirror_mode": {
        "name": "r",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
