{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "# Install required R packages (if needed)\n",
        "pkgs <- c(\"keras3\", \"dplyr\", \"fs\", \"tfdatasets\")\n",
        "to_install <- pkgs[!vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)]\n",
        "if (length(to_install)) install.packages(to_install)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "library(keras3)\n",
        "library(tfdatasets, exclude = \"shape\")\n",
        "py_require(\"keras-hub\")\n",
        "library(fs)\n",
        "library(dplyr, warn.conflicts = FALSE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "i <- 12\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "display_image <- function(x, ..., max = 255L, margin = 0) {\n",
        "  par(mar = rep(margin, 4))\n",
        "\n",
        "  x |> as.array() |> drop() |>\n",
        "    as.raster(max = max) |>\n",
        "    plot(..., interpolate = FALSE)\n",
        "}\n",
        "\n",
        "display_target <- function(target, ..., offset = TRUE) {\n",
        "  if (offset)\n",
        "    target <- target - 1L                                                       # <1>\n",
        "  display_image(target, max = 2L, ...)\n",
        "}\n",
        "\n",
        "tf_image_load <- function(path, target_size = NULL, ...) {\n",
        "  img <- path |>\n",
        "    tf$io$read_file() |>\n",
        "    tf$io$decode_image(..., expand_animations = FALSE)\n",
        "\n",
        "  if (!is.null(target_size))\n",
        "    img <- img |> tf$image$resize(target_size)\n",
        "\n",
        "  img\n",
        "}\n",
        "\n",
        "make_dataset <- function(image_paths) {\n",
        "  stopifnot(is.data.frame(image_paths),\n",
        "            names(image_paths) == c(\"input\", \"target\"))\n",
        "\n",
        "  tensor_slices_dataset(image_paths) |>\n",
        "    dataset_map(function(example_paths) {\n",
        "\n",
        "      input_image <- example_paths$input |>\n",
        "        tf_image_load(channels = 3L, target_size = img_size)                    # <1>\n",
        "\n",
        "      target <- example_paths$target |>\n",
        "        tf_image_load(channels = 1L, target_size = img_size)                    # <2>\n",
        "\n",
        "      target <- tf$cast(target, \"uint8\") - 1L                                   # <3>\n",
        "\n",
        "      list(input_image, target)\n",
        "    }) |>\n",
        "    dataset_cache() |>                                                          # <4>\n",
        "    dataset_shuffle(buffer_size = nrow(image_paths)) |>                         # <5>\n",
        "    dataset_batch(32)\n",
        "}\n",
        "\n",
        "get_model <- function(img_size, num_classes) {\n",
        "\n",
        "  conv <- function(..., padding = \"same\", activation = \"relu\")                  # <1>\n",
        "    layer_conv_2d(..., padding = padding, activation = activation)\n",
        "\n",
        "  conv_transpose <- function(..., padding = \"same\", activation = \"relu\")        # <1>\n",
        "    layer_conv_2d_transpose(..., padding = padding, activation = activation)\n",
        "\n",
        "  input <- keras_input(shape = c(img_size, 3))\n",
        "  output <- input |>\n",
        "    layer_rescaling(scale = 1/255) |>                                           # <2>\n",
        "    conv(64, 3, strides = 2) |>\n",
        "    conv(64, 3) |>\n",
        "    conv(128, 3, strides = 2) |>\n",
        "    conv(128, 3) |>\n",
        "    conv(256, 3, strides = 2) |>\n",
        "    conv(256, 3) |>\n",
        "    conv_transpose(256, 3) |>\n",
        "    conv_transpose(256, 3, strides = 2) |>\n",
        "    conv_transpose(128, 3) |>\n",
        "    conv_transpose(128, 3, strides = 2) |>\n",
        "    conv_transpose(64, 3) |>\n",
        "    conv_transpose(64, 3, strides = 2) |>\n",
        "    conv(num_classes, 3, activation = \"softmax\")                                # <3>\n",
        "\n",
        "  keras_model(input, output)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "# Split marker for notebook/code extraction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "rm(list = setdiff(ls(), \"display_image\")); gc()\n",
        "import(\"gc\")$collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "py_require(\"keras-hub\")                                                         # <1>\n",
        "\n",
        "keras_hub <- import(\"keras_hub\")                                                # <2>\n",
        "model <- keras_hub$models$ImageSegmenter$from_preset(\"sam_huge_sa1b\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "count_params(model) |> prettyNum(\",\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "path <- get_file(\n",
        "  origin = \"https://s3.amazonaws.com/keras.io/img/book/fruits.jpg\"              # <1>\n",
        ")\n",
        "pil_image <- image_load(path)                                                   # <2>\n",
        "image_array <- image_to_array(pil_image, dtype = \"float32\")                     # <3>\n",
        "str(image_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: true\n",
        "#| fig-cap: A fruit test image for Segment Anything\n",
        "display_image(image_array)                                                      # <1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "image_size <- c(1024, 1024)\n",
        "\n",
        "resize_and_pad <- function(x) {\n",
        "  op_image_resize(x, image_size, pad_to_aspect_ratio = TRUE)\n",
        "}\n",
        "\n",
        "image <- resize_and_pad(image_array)\n",
        "op_shape(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "display_points <- function(coords, color = \"white\") {\n",
        "  stopifnot(is.matrix(coords), ncol(coords) == 2)\n",
        "  coords[, 2] <- image_size[1] - coords[, 2]                                    # <1>\n",
        "  points(coords, col = color, pch = 8, cex = 2, lwd = 2)\n",
        "}\n",
        "\n",
        "display_mask <- function(mask, index = 1,\n",
        "                         color = \"dodgerblue\", alpha = 0.6) {\n",
        "  .[r, g, b] <- col2rgb(color)\n",
        "  color <- rgb(r, g, b, alpha * 255, maxColorValue = 255)\n",
        "\n",
        "  mask <- mask |> as.array() |> drop() |> _[index, , ]\n",
        "  mask[] <- ifelse(mask > 0, color, rgb(0, 0, 0, 0))\n",
        "\n",
        "  .[h, w] <- image_size\n",
        "  rasterImage(mask, 0, 0, h, w, interpolate = FALSE)\n",
        "}\n",
        "\n",
        "display_box <- function(box, ..., color = \"red\", lwd = 2) {\n",
        "  stopifnot(is.matrix(box), dim(box) == c(2, 2))\n",
        "  box[, 2] <- image_size[1] - box[, 2]                                          # <2>\n",
        "  rect(xleft = box[1, 1], ytop = box[1, 2],\n",
        "       xright = box[2, 1], ybottom = box[2, 2],\n",
        "       ..., border = color, lwd = lwd)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: \"A prompt point, landing on a peach\"\n",
        "input_point <- rbind(c(580, 480))                                               # <1>\n",
        "input_label <- 1                                                                # <2>\n",
        "\n",
        "display_image(image)\n",
        "display_points(input_point)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "str(model$input)                                                                # <1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "np <- import(\"numpy\", convert = FALSE)                                          # <1>\n",
        "\n",
        "image |>\n",
        "  np_array(\"float32\") |>\n",
        "  np$expand_dims(0L) |>                                                         # <2>\n",
        "  str()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "outputs <- model |> predict(list(\n",
        "  images = image |> np_array(\"float32\") |> np$expand_dims(0L),\n",
        "  points = input_point |> np_array(\"float32\") |> np$expand_dims(0L),\n",
        "  labels = input_label |> np_array(\"float32\") |> np$expand_dims(0L)\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "str(outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Segmented peach\n",
        "display_image(image)\n",
        "display_mask(outputs$masks)\n",
        "display_points(input_point)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Segmented banana\n",
        "input_label <- 1\n",
        "input_point <- rbind(c(300, 550))\n",
        "\n",
        "outputs <- model |> predict(list(\n",
        "  images = image |> np_array(\"float32\") |> np$expand_dims(0L),\n",
        "  points = input_point |> np_array(\"float32\") |> np$expand_dims(0L),\n",
        "  labels = input_label |> np_array(\"float32\") |> np$expand_dims(0L)\n",
        "))\n",
        "\n",
        "display_image(image)\n",
        "display_mask(outputs$masks)\n",
        "display_points(input_point)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Alternative segmentation masks for the banana prompt\n",
        "par(mfrow = c(1, 3))\n",
        "for (i in 2:4) {\n",
        "  display_image(image)\n",
        "  display_mask(outputs$masks, index = i)\n",
        "  display_points(input_point)\n",
        "  title(paste(\"Mask\", i), col.main= \"white\", line = -1.5)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Box prompt around the mango\n",
        "input_box <- rbind(c(520, 180),                                                 # <1>\n",
        "                   c(770, 420))                                                 # <2>\n",
        "\n",
        "display_image(image)\n",
        "display_box(input_box)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Segmented mango\n",
        "outputs <- model |> predict(list(\n",
        "  images = image |> np_array(\"float32\") |> np$expand_dims(0L),\n",
        "  boxes = input_box |> np_array(\"float32\") |> np$expand_dims(c(0L, 1L))         # <1>\n",
        "))\n",
        "\n",
        "display_image(image)\n",
        "display_box(input_box)\n",
        "display_mask(outputs$masks)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R",
      "version": "4.5.2",
      "mimetype": "text/x-r-source",
      "codemirror_mode": {
        "name": "r",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
