{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "# Install required R packages (if needed)\n",
        "pkgs <- c(\"keras3\", \"dplyr\", \"fs\", \"tfdatasets\", \"tibble\", \"tidyr\")\n",
        "to_install <- pkgs[!vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)]\n",
        "if (length(to_install)) install.packages(to_install)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "library(keras3)\n",
        "library(tfdatasets, exclude = \"shape\")\n",
        "py_require(\"keras-hub\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "library(fs)\n",
        "data_dir <- path(\"pets_dataset\")\n",
        "dir_create(data_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "data_url <- path(\"http://www.robots.ox.ac.uk/~vgg/data/pets/data\")\n",
        "\n",
        "options(timeout = 3600)\n",
        "for (filename in c(\"images.tar.gz\", \"annotations.tar.gz\")) {\n",
        "  download.file(url =  data_url / filename,\n",
        "                destfile = data_dir / filename)\n",
        "  untar(data_dir / filename, exdir = data_dir)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "library(dplyr, warn.conflicts = FALSE)\n",
        "input_dir <- data_dir / \"images\"\n",
        "target_dir <- data_dir / \"annotations/trimaps/\"\n",
        "\n",
        "all_image_paths <- tibble(\n",
        "  input = sort(dir_ls(input_dir, glob = \"*.jpg\")),\n",
        "  target = sort(dir_ls(target_dir, glob = \"*.png\", all = FALSE))                # <1>\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Helper to display an image tensor\n",
        "display_image <- function(x, ..., max = 255L, margin = 0) {\n",
        "  par(mar = rep(margin, 4))\n",
        "\n",
        "  x |> as.array() |> drop() |>\n",
        "    as.raster(max = max) |>\n",
        "    plot(..., interpolate = FALSE)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: An example image\n",
        "all_image_paths$input[10] |>                                                    # <1>\n",
        "  image_load() |> image_to_array() |>\n",
        "  display_image()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: The corresponding target mask\n",
        "display_target <- function(target, ..., offset = TRUE) {\n",
        "  if (offset)\n",
        "    target <- target - 1L                                                       # <1>\n",
        "  display_image(target, max = 2L, ...)\n",
        "}\n",
        "\n",
        "all_image_paths$target[10] |>\n",
        "  image_load(color_mode = \"grayscale\") |>                                       # <2>\n",
        "  image_to_array() |>\n",
        "  display_target()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Preparing the dataset\n",
        "library(tfdatasets, exclude = \"shape\")\n",
        "\n",
        "img_size <- shape(200, 200)\n",
        "\n",
        "tf_image_load <- function(path, target_size = NULL, ...) {\n",
        "  img <- path |>\n",
        "    tf$io$read_file() |>\n",
        "    tf$io$decode_image(..., expand_animations = FALSE)\n",
        "\n",
        "  if (!is.null(target_size))\n",
        "    img <- img |> tf$image$resize(target_size)\n",
        "\n",
        "  img\n",
        "}\n",
        "\n",
        "make_dataset <- function(image_paths) {\n",
        "  stopifnot(is.data.frame(image_paths),\n",
        "            names(image_paths) == c(\"input\", \"target\"))\n",
        "\n",
        "  tensor_slices_dataset(image_paths) |>\n",
        "    dataset_map(function(example_paths) {\n",
        "\n",
        "      input_image <- example_paths$input |>\n",
        "        tf_image_load(channels = 3L, target_size = img_size)                    # <1>\n",
        "\n",
        "      target <- example_paths$target |>\n",
        "        tf_image_load(channels = 1L, target_size = img_size)                    # <2>\n",
        "\n",
        "      target <- tf$cast(target, \"uint8\") - 1L                                   # <3>\n",
        "\n",
        "      list(input_image, target)\n",
        "    }) |>\n",
        "    dataset_cache() |>                                                          # <4>\n",
        "    dataset_shuffle(buffer_size = nrow(image_paths)) |>                         # <5>\n",
        "    dataset_batch(32)\n",
        "}\n",
        "\n",
        "num_val_samples <- 1000                                                         # <6>\n",
        "\n",
        "image_paths <- all_image_paths |>\n",
        "  dplyr::mutate(\n",
        "    use = ifelse(sample.int(n()) > num_val_samples, \"train\", \"val\")             # <7>\n",
        "  ) |>\n",
        "  tidyr::nest(.by = use) |>\n",
        "  tibble::deframe()\n",
        "\n",
        "train_ds <- make_dataset(image_paths$train)                                     # <8>\n",
        "val_ds   <- make_dataset(image_paths$val)                                       # <8>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# example_paths <- tensor_slices_dataset(image_paths) |>\n",
        "#   as_iterator() |> iter_next()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# tensor_slices_dataset(image_paths$train) |>\n",
        "#   dataset_map(function(example_paths) {\n",
        "#     print(example_paths)\n",
        "#     browser()\n",
        "#   })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "batch <- train_ds |> as_iterator() |> iter_next()\n",
        "str(batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: A batch of segmentation inputs and masks\n",
        ".[images, targets] <- batch\n",
        "par(mfrow = c(4, 8))\n",
        "for (i in 1:16) {\n",
        "  images@r[i] |> display_image()\n",
        "  targets@r[i] |> display_target(offset = FALSE)                                # <1>\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "get_model <- function(img_size, num_classes) {\n",
        "\n",
        "  conv <- function(..., padding = \"same\", activation = \"relu\")                  # <1>\n",
        "    layer_conv_2d(..., padding = padding, activation = activation)\n",
        "\n",
        "  conv_transpose <- function(..., padding = \"same\", activation = \"relu\")        # <1>\n",
        "    layer_conv_2d_transpose(..., padding = padding, activation = activation)\n",
        "\n",
        "  input <- keras_input(shape = c(img_size, 3))\n",
        "  output <- input |>\n",
        "    layer_rescaling(scale = 1/255) |>                                           # <2>\n",
        "    conv(64, 3, strides = 2) |>\n",
        "    conv(64, 3) |>\n",
        "    conv(128, 3, strides = 2) |>\n",
        "    conv(128, 3) |>\n",
        "    conv(256, 3, strides = 2) |>\n",
        "    conv(256, 3) |>\n",
        "    conv_transpose(256, 3) |>\n",
        "    conv_transpose(256, 3, strides = 2) |>\n",
        "    conv_transpose(128, 3) |>\n",
        "    conv_transpose(128, 3, strides = 2) |>\n",
        "    conv_transpose(64, 3) |>\n",
        "    conv_transpose(64, 3, strides = 2) |>\n",
        "    conv(num_classes, 3, activation = \"softmax\")                                # <3>\n",
        "\n",
        "  keras_model(input, output)\n",
        "}\n",
        "\n",
        "model <- get_model(img_size = img_size, num_classes = 3)\n",
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "foreground_iou <- metric_iou(\n",
        "  num_classes = 3,                                                              # <1>\n",
        "  target_class_ids = c(0),                                                      # <2>\n",
        "  name = \"foreground_iou\",\n",
        "  sparse_y_true = TRUE,                                                         # <3>\n",
        "  sparse_y_pred = FALSE,                                                        # <4>\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model |> compile(\n",
        "  optimizer = \"adam\",\n",
        "  loss = \"sparse_categorical_crossentropy\",\n",
        "  metrics = foreground_iou\n",
        ")\n",
        "\n",
        "callbacks <- list(\n",
        "  callback_model_checkpoint(\"oxford_segmentation.keras\", save_best_only = TRUE)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "history <- model |> fit(\n",
        "  train_ds,\n",
        "  epochs = 50,\n",
        "  callbacks = callbacks,\n",
        "  validation_data = val_ds\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Displaying training and validation loss curves\n",
        "#| eval: true\n",
        "plot(history, metrics = \"loss\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model <- load_model(\"oxford_segmentation.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: \"A test image, its predicted segmentation mask, and its target mask\"\n",
        "i <- 12\n",
        "test_image <- image_paths$val$input[i] |>\n",
        "  tf_image_load(channels = 3L, target_size = img_size)\n",
        "\n",
        "test_mask <- image_paths$val$target[i] |>\n",
        "  tf_image_load(channels = 1L, target_size = img_size) |>\n",
        "  tf$subtract(1)\n",
        "\n",
        "predicted_mask_probs <- model(test_image@r[newaxis])\n",
        "predicted_mask <- op_argmax(predicted_mask_probs, axis = -1,\n",
        "                            zero_indexed = TRUE)                                # <1>\n",
        "\n",
        "par(mfrow = c(1, 3))\n",
        "display_image(test_image)\n",
        "display_target(predicted_mask, offset = FALSE)\n",
        "display_target(test_mask, offset = FALSE)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R",
      "version": "4.5.2",
      "mimetype": "text/x-r-source",
      "codemirror_mode": {
        "name": "r",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
