{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "# Install required R packages (if needed)\n",
        "pkgs <- c(\"keras3\", \"dplyr\", \"fs\", \"glue\", \"tfdatasets\", \"tibble\")\n",
        "to_install <- pkgs[!vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)]\n",
        "if (length(to_install)) install.packages(to_install)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "library(keras3)\n",
        "library(tfdatasets, exclude = \"shape\")\n",
        "keras3::use_backend(\"tensorflow\")\n",
        "reticulate::py_require(\"keras-hub\")\n",
        "library(fs)\n",
        "library(glue)\n",
        "library(tfdatasets, exclude = c(\"shape\"))                                       # <1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "batch_size <- 32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "make_subset <- function(subset_name, start_index, end_index) {                  # <3>\n",
        "  for (category in c(\"dog\", \"cat\")) {\n",
        "    file_name <- glue(\"{category}.{start_index:end_index}.jpg\")\n",
        "    dir_create(new_base_dir / subset_name / category)\n",
        "    file_copy(original_dir / file_name,\n",
        "              new_base_dir / subset_name / category / file_name)\n",
        "  }\n",
        "}\n",
        "\n",
        "data_augmentation <- function(images, targets) {                                # <2>\n",
        "  for (layer in data_augmentation_layers)\n",
        "    images <- layer(images)\n",
        "  list(images, targets)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "library(fs)\n",
        "library(tfdatasets, exclude = \"shape\")\n",
        "\n",
        "new_base_dir <- path(\"dogs_vs_cats_small\")\n",
        "if (!dir_exists(new_base_dir / \"train\")) {\n",
        "  stop(\n",
        "    \"Missing directory: 'dogs_vs_cats_small/train'. Run the earlier section that builds the subsampled dataset first.\",\n",
        "    call. = FALSE\n",
        "  )\n",
        "}\n",
        "\n",
        "image_size <- shape(180, 180)\n",
        "batch_size <- 32\n",
        "\n",
        "train_dataset <-\n",
        "  image_dataset_from_directory(new_base_dir / \"train\",\n",
        "                               image_size = image_size,\n",
        "                               batch_size = batch_size)\n",
        "validation_dataset <-\n",
        "  image_dataset_from_directory(new_base_dir / \"validation\",\n",
        "                               image_size = image_size,\n",
        "                               batch_size = batch_size)\n",
        "test_dataset <-\n",
        "  image_dataset_from_directory(new_base_dir / \"test\",\n",
        "                               image_size = image_size,\n",
        "                               batch_size = batch_size)\n",
        "\n",
        "data_augmentation_layers <- list(\n",
        "  layer_random_flip(, \"horizontal\"),\n",
        "  layer_random_rotation(, 0.1),\n",
        "  layer_random_zoom(, 0.2)\n",
        ")\n",
        "\n",
        "data_augmentation <- function(images, targets) {\n",
        "  for (layer in data_augmentation_layers)\n",
        "    images <- layer(images)\n",
        "  list(images, targets)\n",
        "}\n",
        "\n",
        "augmented_train_dataset <- train_dataset |>\n",
        "  dataset_map(data_augmentation, num_parallel_calls = 8) |>\n",
        "  dataset_prefetch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Instantiating the Xception convolutional base\n",
        "py_require(\"keras-hub\")\n",
        "\n",
        "keras_hub <- import(\"keras_hub\")\n",
        "conv_base <- keras_hub$models$Backbone$from_preset(\"xception_41_imagenet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "preprocessor <- keras_hub$layers$ImageConverter$from_preset(\n",
        "  \"xception_41_imagenet\",\n",
        "  image_size = shape(180, 180)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Extracting image features and corresponding labels\n",
        "get_features_and_labels <- function(dataset) {\n",
        "  dataset |>\n",
        "    as_array_iterator() |>\n",
        "    iterate(function(batch) {\n",
        "      .[images, labels] <- batch\n",
        "      preprocessed_images <- preprocessor(images)\n",
        "      features <- conv_base |> predict(preprocessed_images, verbose = 0)\n",
        "      tibble::tibble(features, labels)\n",
        "    }) |>\n",
        "    dplyr::bind_rows()\n",
        "}\n",
        "\n",
        ".[train_features, train_labels] <- get_features_and_labels(train_dataset)\n",
        ".[val_features, val_labels] <- get_features_and_labels(validation_dataset)\n",
        ".[test_features, test_labels] <- get_features_and_labels(test_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "dim(train_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hide\n",
        "#| lst-cap: Defining and training the densely connected classifier\n",
        "inputs <- keras_input(shape = c(6, 6, 2048))\n",
        "outputs <- inputs |>\n",
        "  layer_global_average_pooling_2d() |>                                          # <1>\n",
        "  layer_dense(256, activation = \"relu\") |>\n",
        "  layer_dropout(0.25) |>\n",
        "  layer_dense(1, activation = \"sigmoid\")\n",
        "\n",
        "model <- keras_model(inputs, outputs)\n",
        "\n",
        "model |> compile(\n",
        "  loss = \"binary_crossentropy\",\n",
        "  optimizer = \"adam\",\n",
        "  metrics = \"accuracy\"\n",
        ")\n",
        "\n",
        "callbacks <- list(\n",
        "  callback_model_checkpoint(\n",
        "    filepath = \"feature_extraction.keras\",\n",
        "    save_best_only = TRUE,\n",
        "    monitor = \"val_loss\"\n",
        "  )\n",
        ")\n",
        "\n",
        "history <- model |> fit(\n",
        "  train_features, train_labels,\n",
        "  epochs = 10,\n",
        "  validation_data = list(val_features, val_labels),\n",
        "  callbacks = callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Training and validation metrics for plain feature extraction\n",
        "#| lst-cap: Plotting the results\n",
        "plot(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "test_model <- load_model(\"feature_extraction.keras\")\n",
        "result <- evaluate(test_model, test_features, test_labels)\n",
        "cat(sprintf(\"Test accuracy: %.3f\\n\", result$accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Creating the frozen convolutional base\n",
        "conv_base <- keras_hub$models$Backbone$from_preset(\n",
        "  \"xception_41_imagenet\",\n",
        "  trainable = FALSE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Printing trainable weights before and after freezing\n",
        "unfreeze_weights(conv_base)                                                     # <1>\n",
        "length(conv_base$trainable_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "freeze_weights(conv_base)                                                       # <1>\n",
        "length(conv_base$trainable_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "inputs <- keras_input(shape=c(180, 180, 3))\n",
        "outputs <- inputs |>\n",
        "  preprocessor() |>\n",
        "  conv_base() |>\n",
        "  layer_global_average_pooling_2d() |>\n",
        "  layer_dense(256) |>\n",
        "  layer_dropout(0.25) |>\n",
        "  layer_dense(1, activation = \"sigmoid\")\n",
        "model <- keras_model(inputs, outputs)\n",
        "model |> compile(\n",
        "  loss = \"binary_crossentropy\",\n",
        "  optimizer = \"adam\",\n",
        "  metrics = \"accuracy\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hide\n",
        "callbacks <- list(\n",
        "  callback_model_checkpoint(\n",
        "    filepath = \"feature_extraction_with_data_augmentation.keras\",\n",
        "    save_best_only = TRUE,\n",
        "    monitor = \"val_loss\"\n",
        "  )\n",
        ")\n",
        "\n",
        "history <- model |> fit(\n",
        "  augmented_train_dataset,\n",
        "  epochs = 30,\n",
        "  validation_data = validation_dataset,\n",
        "  callbacks = callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Training and validation metrics for feature extraction with data augmentation\n",
        "plot(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Evaluating the model on the test set\n",
        "test_model <- load_model(\"feature_extraction_with_data_augmentation.keras\")\n",
        "result <- evaluate(test_model, test_dataset)\n",
        "cat(sprintf(\"Test accuracy: %.3f\\n\", result$accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "conv_base$trainable <- TRUE\n",
        "for (layer in head(conv_base$layers, -4))\n",
        "  layer$trainable <- FALSE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "unfreeze_weights(conv_base, from = -4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hide\n",
        "#| lst-cap: Fine-tuning the model\n",
        "model |> compile(\n",
        "  loss = \"binary_crossentropy\",\n",
        "  optimizer = optimizer_adam(learning_rate = 1e-5),\n",
        "  metrics = \"accuracy\"\n",
        ")\n",
        "\n",
        "callbacks <- list(\n",
        "  callback_model_checkpoint(\n",
        "    filepath = \"fine_tuning.keras\",\n",
        "    save_best_only = TRUE,\n",
        "    monitor = \"val_loss\"\n",
        "  )\n",
        ")\n",
        "\n",
        "history <- model |> fit(\n",
        "  augmented_train_dataset,\n",
        "  epochs = 30,\n",
        "  validation_data = validation_dataset,\n",
        "  callbacks = callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model <- load_model(\"fine_tuning.keras\")\n",
        "result <-  evaluate(model, test_dataset)\n",
        "cat(sprintf(\"Test accuracy: %.3f\\n\", result$accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Training and validation metrics for fine-tuning\n",
        "plot(history)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R",
      "version": "4.5.2",
      "mimetype": "text/x-r-source",
      "codemirror_mode": {
        "name": "r",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
