{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "# Install required R packages (if needed)\n",
        "pkgs <- c(\"keras3\", \"envir\", \"fs\", \"glue\", \"tfdatasets\", \"zip\")\n",
        "to_install <- pkgs[!vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)]\n",
        "if (length(to_install)) install.packages(to_install)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "library(keras3)\n",
        "library(tfdatasets, exclude = \"shape\")\n",
        "\n",
        "keras3::use_backend(\"tensorflow\")\n",
        "reticulate::py_require(\"keras-hub\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Instantiating a small convnet\n",
        "library(keras3)\n",
        "\n",
        "inputs <- keras_input(shape = c(28, 28, 1))\n",
        "outputs <- inputs |>\n",
        "  layer_conv_2d(filters = 64, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_max_pooling_2d(pool_size = 2) |>\n",
        "  layer_conv_2d(filters = 128, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_max_pooling_2d(pool_size = 2) |>\n",
        "  layer_conv_2d(filters = 256, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_global_average_pooling_2d() |>\n",
        "  layer_dense(10, activation = \"softmax\")\n",
        "\n",
        "model <- keras_model(inputs = inputs, outputs = outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"Displaying the model's summary\"\n",
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hide\n",
        "#| lst-cap: Training the convnet on MNIST images\n",
        ".[.[train_images, train_labels],\n",
        "  .[test_images, test_labels]] <- dataset_mnist()\n",
        "train_images <- array_reshape(train_images, c(-1, 28, 28, 1)) / 255             # <1>\n",
        "test_images  <- array_reshape(test_images, c(-1, 28, 28, 1)) / 255              # <1>\n",
        "\n",
        "model |> compile(\n",
        "  optimizer = \"rmsprop\",\n",
        "  loss = \"sparse_categorical_crossentropy\",\n",
        "  metrics = c(\"accuracy\")\n",
        ")\n",
        "model |> fit(train_images, train_labels, epochs = 5, batch_size = 64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Evaluating the convnet\n",
        "result <- evaluate(model, test_images, test_labels)\n",
        "cat(\"Test accuracy:\", result$accuracy, \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Incorrectly structured convnet missing max pooling layers\n",
        "inputs <- keras_input(shape = c(28, 28, 1))\n",
        "outputs <- inputs |>\n",
        "  layer_conv_2d(filters = 64, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_conv_2d(filters = 128, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_conv_2d(filters = 256, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_global_average_pooling_2d() |>\n",
        "  layer_dense(10, activation = \"softmax\")\n",
        "\n",
        "model_no_max_pool <- keras_model(inputs = inputs, outputs = outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model_no_max_pool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# library(fs)\n",
        "# dir_create(\"~/.kaggle\")\n",
        "# file_move(\"~/Downloads/kaggle.json\", \"~/.kaggle/\")\n",
        "# file_chmod(\"~/.kaggle/kaggle.json\", \"0600\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# reticulate::uv_run_tool(\"kaggle competitions download -c dogs-vs-cats\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# py_require(\"kagglehub\")\n",
        "# kagglehub <- import(\"kagglehub\")\n",
        "# kagglehub$login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# kagglehub$competition_download(\"dogs-vs-cats\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "library(fs)\n",
        "original_dir <- path(\"dogs-vs-cats/train\")\n",
        "if (!dir_exists(original_dir)) {\n",
        "  stop(\n",
        "    \"Missing dataset directory: 'dogs-vs-cats/train'. Download/unzip the Kaggle Dogs vs Cats dataset first.\",\n",
        "    call. = FALSE\n",
        "  )\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "# zip::unzip('dogs-vs-cats.zip', exdir = \"dogs-vs-cats\", files = \"train.zip\")\n",
        "# zip::unzip(\"dogs-vs-cats/train.zip\", exdir = \"dogs-vs-cats\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "fs::dir_tree(\"dogs_vs_cats_small/\", recurse = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"Copying images to training, validation, and test directories\"\n",
        "library(fs)\n",
        "library(glue)\n",
        "\n",
        "original_dir <- path(\"dogs-vs-cats/train\")                                      # <1>\n",
        "new_base_dir <- path(\"dogs_vs_cats_small\")                                      # <2>\n",
        "\n",
        "make_subset <- function(subset_name, start_index, end_index) {                  # <3>\n",
        "  for (category in c(\"dog\", \"cat\")) {\n",
        "    file_name <- glue(\"{category}.{start_index:end_index}.jpg\")\n",
        "    dir_create(new_base_dir / subset_name / category)\n",
        "    file_copy(original_dir / file_name,\n",
        "              new_base_dir / subset_name / category / file_name)\n",
        "  }\n",
        "}\n",
        "\n",
        "make_subset(\"train\", start_index = 1, end_index = 1000)                         # <4>\n",
        "make_subset(\"validation\", start_index = 1001, end_index = 1500)                 # <5>\n",
        "make_subset(\"test\", start_index = 1501, end_index = 2500)                       # <6>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Instantiating a small convnet for dogs vs. cats classification\n",
        "inputs <- keras_input(shape = c(180, 180, 3))                                   # <1>\n",
        "outputs <- inputs |>\n",
        "  layer_rescaling(1 / 255) |>                                                   # <2>\n",
        "  layer_conv_2d(filters = 32, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_max_pooling_2d(pool_size = 2) |>\n",
        "  layer_conv_2d(filters = 64, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_max_pooling_2d(pool_size = 2) |>\n",
        "  layer_conv_2d(filters = 128, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_max_pooling_2d(pool_size = 2) |>\n",
        "  layer_conv_2d(filters = 256, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_max_pooling_2d(pool_size = 2) |>\n",
        "  layer_conv_2d(filters = 512, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_global_average_pooling_2d() |>                                          # <3>\n",
        "  layer_dense(1, activation = \"sigmoid\")\n",
        "\n",
        "model <- keras_model(inputs, outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Configuring the model for training\n",
        "model |> compile(\n",
        "  loss = \"binary_crossentropy\",\n",
        "  optimizer = \"adam\",\n",
        "  metrics = \"accuracy\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hide\n",
        "#| lst-cap: \"Using `image_dataset_from_directory()` to read images from directories\"\n",
        "image_size <- shape(180, 180)\n",
        "batch_size <- 32\n",
        "\n",
        "train_dataset <-\n",
        "  image_dataset_from_directory(new_base_dir / \"train\",\n",
        "                               image_size = image_size,\n",
        "                               batch_size = batch_size)\n",
        "validation_dataset <-\n",
        "  image_dataset_from_directory(new_base_dir / \"validation\",\n",
        "                               image_size = image_size,\n",
        "                               batch_size = batch_size)\n",
        "test_dataset <-\n",
        "  image_dataset_from_directory(new_base_dir / \"test\",\n",
        "                               image_size = image_size,\n",
        "                               batch_size = batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "example_array <- array(seq(100*6), c(100, 6))\n",
        "head(example_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Instantiating a Dataset from an R array\n",
        "library(tfdatasets, exclude = c(\"shape\"))                                       # <1>\n",
        "\n",
        "dataset <- tensor_slices_dataset(example_array)                                 # <2>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Iterating on a dataset\n",
        "dataset_iterator <- as_iterator(dataset)\n",
        "for (i in 1:3) {\n",
        "  element <- iter_next(dataset_iterator)\n",
        "  print(element)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Batching a dataset\n",
        "batched_dataset <- dataset |> dataset_batch(3)\n",
        "batched_dataset_iterator <- as_iterator(batched_dataset)\n",
        "for (i in 1:3) {\n",
        "  element <- iter_next(batched_dataset_iterator)\n",
        "  print(element)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"Applying a Dataset transformation using `dataset_map()`\"\n",
        "reshaped_dataset <- dataset |>\n",
        "  dataset_map(\\(element) tf$reshape(element, shape(2, 3)))\n",
        "\n",
        "reshaped_dataset_iterator <- as_iterator(reshaped_dataset)\n",
        "for (i in 1:3) {\n",
        "  element <- iter_next(reshaped_dataset_iterator)\n",
        "  print(element)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"Displaying the shapes yielded by the `Dataset`\"\n",
        ".[data_batch, labels_batch] <- train_dataset |> as_iterator() |> iter_next()\n",
        "op_shape(data_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "op_shape(labels_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hide\n",
        "#| lst-cap: \"Fitting the model using a `Dataset`\"\n",
        "callbacks <- list(\n",
        "  callback_model_checkpoint(\n",
        "    filepath = \"convnet_from_scratch.keras\",\n",
        "    save_best_only = TRUE,\n",
        "    monitor = \"val_loss\"\n",
        "  )\n",
        ")\n",
        "\n",
        "history <- model |> fit(\n",
        "  train_dataset,\n",
        "  epochs = 50,\n",
        "  validation_data = validation_dataset,\n",
        "  callbacks = callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Displaying curves of loss and accuracy during training\n",
        "#| fig-cap: Training and validation metrics for a simple convnet\n",
        "plot(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Evaluating the model on the test set\n",
        "test_model <- load_model(\"convnet_from_scratch.keras\")\n",
        "result <- evaluate(test_model, test_dataset)\n",
        "cat(sprintf(\"Test accuracy: %.3f\\n\", result$accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Defining a data augmentation stage\n",
        "data_augmentation_layers <- list(                                               # <1>\n",
        "  layer_random_flip(, \"horizontal\"),\n",
        "  layer_random_rotation(, 0.1),\n",
        "  layer_random_zoom(, 0.2)\n",
        ")\n",
        "\n",
        "data_augmentation <- function(images, targets) {                                # <2>\n",
        "  for (layer in data_augmentation_layers)\n",
        "    images <- layer(images)\n",
        "  list(images, targets)\n",
        "}\n",
        "\n",
        "augmented_train_dataset <- train_dataset |>\n",
        "  dataset_map(data_augmentation, num_parallel_calls = 8) |>                     # <3>\n",
        "  dataset_prefetch()                                                            # <4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# layer <- layer_random_flip(, \"horizontal\")\n",
        "# result <- layer(object)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# result <- object |> layer_random_flip(\"horizontal\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Randomly augmented training images\n",
        "#| fig-cap: Generating variations of a very good boy via random data augmentation\n",
        "batch <- train_dataset |> as_iterator() |> iter_next()\n",
        ".[images, labels] <- batch\n",
        "\n",
        "par(mfrow = c(3, 3), mar = rep(.5, 4))\n",
        "\n",
        "image <- images[1, , , ]\n",
        "plot(as.raster(image, max = 255))                                               # <1>\n",
        "\n",
        "for (i in 2:9) {\n",
        "  .[augmented_images, ..] <- data_augmentation(images, NULL)                    # <2>\n",
        "  augmented_image <- augmented_images@r[1] |> as.array()                        # <3>\n",
        "  plot(as.raster(augmented_image, max = 255))                                   # <3>\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Defining a new convnet that includes dropout\n",
        "inputs <- keras_input(shape = c(180, 180, 3))\n",
        "outputs <- inputs |>\n",
        "  layer_rescaling(1 / 255) |>\n",
        "  layer_conv_2d(filters = 32, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_max_pooling_2d(pool_size = 2) |>\n",
        "  layer_conv_2d(filters = 64, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_max_pooling_2d(pool_size = 2) |>\n",
        "  layer_conv_2d(filters = 128, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_max_pooling_2d(pool_size = 2) |>\n",
        "  layer_conv_2d(filters = 256, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_max_pooling_2d(pool_size = 2) |>\n",
        "  layer_conv_2d(filters = 512, kernel_size = 3, activation = \"relu\") |>\n",
        "  layer_global_average_pooling_2d() |>\n",
        "  layer_dropout(0.25) |>\n",
        "  layer_dense(1, activation = \"sigmoid\")\n",
        "\n",
        "model <- keras_model(inputs, outputs)\n",
        "\n",
        "model |> compile(\n",
        "  loss = \"binary_crossentropy\",\n",
        "  optimizer = \"adam\",\n",
        "  metrics = \"accuracy\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hide\n",
        "#| lst-cap: Training the regularized convnet on augmented images\n",
        "callbacks <- list(\n",
        "  callback_model_checkpoint(\n",
        "    filepath = \"convnet_from_scratch_with_augmentation.keras\",\n",
        "    save_best_only = TRUE,\n",
        "    monitor = \"val_loss\"\n",
        "  )\n",
        ")\n",
        "\n",
        "history <- model |> fit(\n",
        "  augmented_train_dataset,\n",
        "  epochs = 100,                                                                 # <1>\n",
        "  validation_data = validation_dataset,\n",
        "  callbacks = callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Training and validation metrics with data augmentation\n",
        "plot(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Evaluating the model on the test set\n",
        "test_model <- load_model(\"convnet_from_scratch_with_augmentation.keras\")\n",
        "result <- evaluate(test_model, test_dataset)\n",
        "cat(sprintf(\"Test accuracy: %.3f\\n\", result$accuracy))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R",
      "version": "4.5.2",
      "mimetype": "text/x-r-source",
      "codemirror_mode": {
        "name": "r",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
