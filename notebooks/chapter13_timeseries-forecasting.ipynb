{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "# Install required R packages (if needed)\n",
        "pkgs <- c(\"keras3\", \"conflicted\", \"dplyr\", \"generics\", \"purrr\", \"tfdatasets\", \"tibble\", \"withr\", \"zip\")\n",
        "to_install <- pkgs[!vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)]\n",
        "if (length(to_install)) install.packages(to_install)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "library(tensorflow, exclude = c(\"shape\", \"set_random_seed\"))\n",
        "library(tfdatasets, exclude = \"shape\")\n",
        "library(dplyr, warn.conflicts = FALSE)\n",
        "library(keras3)\n",
        "use_backend(\"jax\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "library(tensorflow, exclude = c(\"shape\", \"set_random_seed\"))\n",
        "library(tfdatasets, exclude = \"shape\")\n",
        "library(dplyr, warn.conflicts = FALSE)\n",
        "library(keras3)\n",
        "\n",
        "url <- paste0(\n",
        "  \"https://s3.amazonaws.com/keras-datasets/\",\n",
        "  \"jena_climate_2009_2016.csv.zip\"\n",
        ")\n",
        "get_file(origin = url) |>\n",
        "  zip::unzip(\"jena_climate_2009_2016.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Peeking at the Jena weather dataset file\n",
        "writeLines(readLines(\"jena_climate_2009_2016.csv\", 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hide\n",
        "#| lst-cap: Reading in the data\n",
        "withr::with_package(\"readr\", {\n",
        "  full_df <- read_csv(\n",
        "    \"jena_climate_2009_2016.csv\",\n",
        "    locale = locale(tz = \"Etc/GMT+1\"),\n",
        "    col_types = cols(\n",
        "      `Date Time` = col_datetime(\"%d.%m.%Y %H:%M:%S\"),\n",
        "      .default = col_double()\n",
        "    )\n",
        "  )\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Inspecting the data in the Jena weather dataset\n",
        "tibble::glimpse(full_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Plotting the temperature timeseries\n",
        "#| fig-cap: Temperature over the full temporal range of the dataset (ºC)\n",
        "plot(`T (degC)` ~ `Date Time`, data = full_df, pch = 20, cex = .3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Plotting the first 10 days of the temperature timeseries\n",
        "#| fig-cap: Temperature over the first 10 days of the dataset (ºC)\n",
        "plot(`T (degC)` ~ `Date Time`, data = full_df[1:1440, ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| results: hold\n",
        "#| lst-cap: Computing how many samples to use for each data split\n",
        "num_train_samples <- round(nrow(full_df) * .5)\n",
        "num_val_samples <- round(nrow(full_df) * 0.25)\n",
        "num_test_samples <- nrow(full_df) - num_train_samples - num_val_samples\n",
        "\n",
        "train_df <- full_df[seq(num_train_samples), ]\n",
        "\n",
        "val_df <- full_df[seq(from = nrow(train_df) + 1,\n",
        "                      length.out = num_val_samples), ]\n",
        "\n",
        "test_df <- full_df[seq(to = nrow(full_df),\n",
        "                       length.out = num_test_samples), ]\n",
        "\n",
        "cat(\"num_train_samples:\", nrow(train_df), \"\\n\")\n",
        "cat(\"num_val_samples:\", nrow(val_df), \"\\n\")\n",
        "cat(\"num_test_samples:\", nrow(test_df), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Normalizing the data\n",
        "input_data_colnames <- names(full_df) |> setdiff(c(\"Date Time\"))\n",
        "normalization_values <- train_df[input_data_colnames] |>\n",
        "  lapply(\\(col) list(mean = mean(col), sd = sd(col)))\n",
        "\n",
        "str(normalization_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "normalize_input_data <- function(df) {\n",
        "  purrr::map2(df, normalization_values[names(df)], \\(col, nv) {\n",
        "    (col - nv$mean) / nv$sd\n",
        "  }) |> as_tibble()\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "int_sequence <- seq(10)\n",
        "dummy_dataset <- timeseries_dataset_from_array(\n",
        "  data = head(int_sequence, -3),\n",
        "  targets = tail(int_sequence, -3),\n",
        "  sequence_length = 3,\n",
        "  batch_size = 2\n",
        ")\n",
        "\n",
        "dummy_dataset_iterator <- as_array_iterator(dummy_dataset)\n",
        "\n",
        "repeat {\n",
        "  batch <- iter_next(dummy_dataset_iterator)\n",
        "  if (is.null(batch)) break\n",
        "  .[inputs, targets] <- batch\n",
        "  for (r in 1:nrow(inputs))\n",
        "    cat(sprintf(\"input: [ %s ]  target: %s\\n\",\n",
        "                paste(inputs[r, ], collapse = \" \"), targets[r]))\n",
        "  cat(strrep(\"-\", 27), \"\\n\")\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: \"Instantiating datasets for training, validation, and testing\"\n",
        "sampling_rate <- 6\n",
        "sequence_length <- 120\n",
        "delay <- sampling_rate * (sequence_length + 24 - 1)\n",
        "batch_size <- 256\n",
        "\n",
        "df_to_inputs_and_targets <- function(df) {\n",
        "  inputs <- df[input_data_colnames] |>\n",
        "    normalize_input_data() |>\n",
        "    as.matrix()\n",
        "\n",
        "  targets <- as.array(df$`T (degC)`)\n",
        "\n",
        "  list(\n",
        "    head(inputs, -delay),\n",
        "    tail(targets, -delay)\n",
        "  )\n",
        "}\n",
        "\n",
        "make_dataset <- function(df) {\n",
        "  .[inputs, targets] <- df_to_inputs_and_targets(df)\n",
        "\n",
        "  timeseries_dataset_from_array(\n",
        "    inputs, targets,\n",
        "    sampling_rate = sampling_rate,\n",
        "    sequence_length = sequence_length,\n",
        "    shuffle = TRUE,\n",
        "    batch_size = batch_size\n",
        "  )\n",
        "}\n",
        "\n",
        "train_dataset <- make_dataset(train_df)\n",
        "val_dataset <- make_dataset(val_df)\n",
        "test_dataset <- make_dataset(test_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Inspecting the output of one of our datasets\n",
        ".[samples, targets] <- iter_next(as_iterator(train_dataset))\n",
        "cat(\"samples shape: \", format(samples$shape), \"\\n\",\n",
        "    \"targets shape: \", format(targets$shape), \"\\n\", sep = \"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# mean(abs(preds - targets))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Computing the common-sense baseline MAE\n",
        "evaluate_naive_method <- function(dataset) {\n",
        "\n",
        "  .[temp_sd = sd, temp_mean = mean] <- normalization_values$`T (degC)`\n",
        "  unnormalize_temperature <- function(x) {\n",
        "    (x * temp_sd) + temp_mean\n",
        "  }\n",
        "\n",
        "  temp_col_idx <- match(\"T (degC)\", input_data_colnames)\n",
        "\n",
        "  reduction <- dataset |>\n",
        "    dataset_unbatch() |>\n",
        "    dataset_map(function(samples, target) {\n",
        "      last_temp_in_input <- samples@r[-1, temp_col_idx]                         # <1>\n",
        "      pred <- unnormalize_temperature(last_temp_in_input)                       # <2>\n",
        "      abs(pred - target)\n",
        "    }) |>\n",
        "    dataset_reduce(\n",
        "      initial_state = list(total_samples_seen = 0L,\n",
        "                           total_abs_error = 0),\n",
        "      reduce_func = function(state, element) {\n",
        "        `add<-` <- `+`\n",
        "        add(state$total_samples_seen) <- 1L\n",
        "        add(state$total_abs_error) <- element\n",
        "        state\n",
        "      }\n",
        "    ) |>\n",
        "    lapply(as.numeric)                                                          # <3>\n",
        "\n",
        "  mae <- with(reduction, total_abs_error / total_samples_seen)                  # <4>\n",
        "  mae\n",
        "}\n",
        "\n",
        "sprintf(\"Validation MAE: %.2f\", evaluate_naive_method(val_dataset))\n",
        "sprintf(\"Test MAE: %.2f\", evaluate_naive_method(test_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Training and evaluating a densely connected model\n",
        "ncol_input_data <- length(input_data_colnames)\n",
        "\n",
        "inputs <- keras_input(shape = c(sequence_length, ncol_input_data))\n",
        "outputs <- inputs |>\n",
        "  layer_reshape(-1) |>                                                          # <1>\n",
        "  layer_dense(16, activation=\"relu\") |>\n",
        "  layer_dense(1)\n",
        "\n",
        "model <- keras_model(inputs, outputs)\n",
        "\n",
        "callbacks = list(\n",
        "  callback_model_checkpoint(\"jena_dense.keras\", save_best_only = TRUE)          # <2>\n",
        ")\n",
        "\n",
        "model |> compile(\n",
        "  optimizer = \"adam\",\n",
        "  loss = \"mse\",\n",
        "  metrics = \"mae\"\n",
        ")\n",
        "\n",
        "history <- model |> fit(\n",
        "  train_dataset,\n",
        "  epochs = 10,\n",
        "  validation_data = val_dataset,\n",
        "  callbacks = callbacks\n",
        ")\n",
        "\n",
        "model <- load_model(\"jena_dense.keras\")                                         # <3>\n",
        "sprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Plotting results\n",
        "#| fig-cap: \"Training and validation MAE on the Jena temperature-forecasting task with a simple, densely connected network\"\n",
        "plot(history, metrics = \"mae\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "inputs <- keras_input(shape = c(sequence_length, ncol_input_data))\n",
        "outputs <- inputs |>\n",
        "  layer_conv_1d(8, 24, activation = \"relu\") |>\n",
        "  layer_max_pooling_1d(2) |>\n",
        "  layer_conv_1d(8, 12, activation = \"relu\") |>\n",
        "  layer_max_pooling_1d(2) |>\n",
        "  layer_conv_1d(8, 6, activation = \"relu\") |>\n",
        "  layer_global_average_pooling_1d() |>\n",
        "  layer_dense(1)\n",
        "model <- keras_model(inputs, outputs)\n",
        "\n",
        "callbacks <- list(\n",
        "  callback_model_checkpoint(\"jena_conv.keras\", save_best_only = TRUE)\n",
        ")\n",
        "\n",
        "model |> compile(\n",
        "  optimizer = \"adam\",\n",
        "  loss = \"mse\",\n",
        "  metrics = \"mae\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "history <- model |> fit(\n",
        "  train_dataset,\n",
        "  epochs = 10,\n",
        "  validation_data = val_dataset,\n",
        "  callbacks = callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model <- load_model(\"jena_conv.keras\")\n",
        "sprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[[\"mae\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Training and validating MAE on the Jena temperature-forecasting task with a 1D convnet\n",
        "plot(history, metrics = \"mae\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: A simple LSTM-based model\n",
        "inputs <- keras_input(shape = c(sequence_length, ncol_input_data))\n",
        "outputs <- inputs |>\n",
        "  layer_lstm(16) |>\n",
        "  layer_dense(1)\n",
        "model <- keras_model(inputs, outputs)\n",
        "\n",
        "callbacks <- list(\n",
        "  callback_model_checkpoint(\"jena_lstm.keras\", save_best_only = TRUE)\n",
        ")\n",
        "\n",
        "compile(model, optimizer = \"adam\", loss = \"mse\", metrics = \"mae\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "history <- model |> fit(\n",
        "  train_dataset,\n",
        "  epochs = 10,\n",
        "  validation_data = val_dataset,\n",
        "  callbacks = callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: \"Training and validation MAE on the Jena temperature-forecasting task with an LSTM-based model (note that we omit epoch 1 on this graph, because the high training MAE [7.75] at epoch 1 would distort the scale)\"\n",
        "local({\n",
        "  p <- plot(history, metrics = \"mae\")\n",
        "  p$data %<>% .[.$epoch > 1, ]\n",
        "  print(p)\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model <- load_model(\"jena_lstm.keras\")\n",
        "sprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[[\"mae\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Pseudocode RNN\n",
        "#| eval: false\n",
        "# state_t <- 0                                                                    # <1>\n",
        "# for (input_t in input_sequence) {                                               # <2>\n",
        "#   output_t <- f(input_t, state_t)\n",
        "#   state_t <- output_t                                                           # <3>\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "#| lst-cap: More detailed pseudocode for the RNN\n",
        "# state_t <- 0\n",
        "# for (input_t in input_sequence) {\n",
        "#   output_t <- activation(dot(W, input_t) + dot(U, state_t) + b)\n",
        "#   state_t <- output_t\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: R implementation of a simple RNN\n",
        "runif_array <- function(dim) array(runif(prod(dim)), dim)\n",
        "\n",
        "timesteps <- 100                                                                # <1>\n",
        "input_features <- 32                                                            # <2>\n",
        "output_features <- 64                                                           # <3>\n",
        "\n",
        "inputs <- runif_array(c(timesteps, input_features))                             # <4>\n",
        "state_t <- array(0, dim = output_features)                                      # <5>\n",
        "W <- runif_array(c(output_features, input_features))                            # <6>\n",
        "U <- runif_array(c(output_features, output_features))                           # <6>\n",
        "b <- runif_array(c(output_features, 1))                                         # <6>\n",
        "outputs <- array(0, dim = c(timesteps, output_features))\n",
        "\n",
        "for(ts in 1:timesteps) {\n",
        "  input_t <- inputs[ts, ]                                                       # <7>\n",
        "  output_t <- tanh( (W %*% input_t) + (U %*% state_t) + b )                     # <8>\n",
        "  outputs[ts, ] <- state_t <- output_t                                          # <9>\n",
        "}\n",
        "\n",
        "final_output_sequence <- outputs                                                # <10>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# output_t <- tanh((W %*% input_t) + (U %*% state_t) + b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: RNN layer that can process sequences of any length\n",
        "num_features <- 14\n",
        "inputs <- keras_input(shape = c(NA, num_features))\n",
        "outputs <- inputs |> layer_simple_rnn(16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: RNN layer that returns only its last output step\n",
        "num_features <- 14\n",
        "steps <- 120\n",
        "inputs <- keras_input(shape = c(steps, num_features))\n",
        "outputs <- inputs |> layer_simple_rnn(16, return_sequences = FALSE)             # <1>\n",
        "op_shape(outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: RNN layer that returns its full output sequence\n",
        "num_features <- 14\n",
        "steps <- 120\n",
        "inputs <- keras_input(shape = c(steps, num_features))\n",
        "outputs <- inputs |> layer_simple_rnn(16, return_sequences = TRUE)              # <1>\n",
        "op_shape(outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Stacking RNN layers\n",
        "inputs <- keras_input(shape = c(steps, num_features))\n",
        "outputs <- inputs |>\n",
        "  layer_simple_rnn(16, return_sequences = TRUE) |>\n",
        "  layer_simple_rnn(16, return_sequences = TRUE) |>\n",
        "  layer_simple_rnn(16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# y <- activation( (state_t %*% U) + (input_t %*% W) + b )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "#| lst-cap: Pseudocode details of the LSTM architecture (1/2)\n",
        "# output_t <-\n",
        "#        activation((state_t %*% Uo) + (input_t %*% Wo) + (c_t %*% Vo) + bo)\n",
        "# i_t <- activation((state_t %*% Ui) + (input_t %*% Wi) + bi)\n",
        "# f_t <- activation((state_t %*% Uf) + (input_t %*% Wf) + bf)\n",
        "# k_t <- activation((state_t %*% Uk) + (input_t %*% Wk) + bk)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "#| lst-cap: Pseudocode details of the LSTM architecture (2/2)\n",
        "# c_t+1 = i_t * k_t + c_t * f_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Training and evaluating a dropout-regularized LSTM\n",
        "inputs <- keras_input(shape = c(sequence_length, ncol_input_data))\n",
        "outputs <- inputs |>\n",
        "  layer_lstm(32, recurrent_dropout = 0.25) |>\n",
        "  layer_dropout(0.5) |>                                                         # <1>\n",
        "  layer_dense(1)\n",
        "model <- keras_model(inputs, outputs)\n",
        "\n",
        "callbacks = list(\n",
        "  callback_model_checkpoint(\"jena_lstm_dropout.keras\", save_best_only = TRUE)\n",
        ")\n",
        "\n",
        "compile(model, optimizer = \"adam\", loss = \"mse\", metrics = \"mae\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "history <- model |> fit(\n",
        "  train_dataset,\n",
        "  epochs = 50,\n",
        "  validation_data = val_dataset,\n",
        "  callbacks = callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Training and validation loss on the Jena temperature-forecasting task with a dropout-regularized LSTM\n",
        "local({\n",
        "  p <- plot(history, metrics = \"mae\")\n",
        "  p$data %<>% .[.$epoch > 1, ]\n",
        "  print(p)\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "inputs <- keras_input(shape = c(sequence_length, num_features))                 # <1>\n",
        "x <- inputs |> layer_lstm(32, recurrent_dropout = 0.2, unroll = TRUE)           # <2>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Training and evaluating a stacked GRU model\n",
        "inputs <- keras_input(shape = c(sequence_length, ncol_input_data))\n",
        "outputs <- inputs |>\n",
        "  layer_gru(32, recurrent_dropout = 0.5, return_sequences = TRUE) |>\n",
        "  layer_gru(32, recurrent_dropout = 0.5) |>\n",
        "  layer_dropout(0.5) |>\n",
        "  layer_dense(1)\n",
        "model <- keras_model(inputs, outputs)\n",
        "\n",
        "callbacks <- list(\n",
        "  callback_model_checkpoint(\n",
        "    \"jena_stacked_gru_dropout.keras\", save_best_only = TRUE\n",
        "  )\n",
        ")\n",
        "\n",
        "model |> compile(optimizer = \"adam\", loss = \"mse\", metrics = \"mae\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "history <- model |> fit(\n",
        "  train_dataset,\n",
        "  epochs = 50,\n",
        "  validation_data = val_dataset,\n",
        "  callbacks = callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: Training and validation loss on the Jena temperature-forecasting task with a stacked GRU network\n",
        "plot(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model <- load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "sprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[[\"mae\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "model <- load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "stacked_gru_dropout_mae <- evaluate(model, test_dataset)[[\"mae\"]]\n",
        "pct_over_naive <- local({\n",
        "  baseline_test_mae_num <- 2.622093\n",
        "  pct <- 100 *\n",
        "    (baseline_test_mae_num - stacked_gru_dropout_mae) /\n",
        "    baseline_test_mae_num\n",
        "  sprintf(\"%.1f\", round(pct, 1))\n",
        "})\n",
        "stacked_gru_dropout_mae %<>% sprintf(\"%.2f\", .)\n",
        "print(paste(\"Test MAE:\", stacked_gru_dropout_mae))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "# dataset <- dataset |>\n",
        "#   dataset_map(\\(samples, targets) {\n",
        "#     list(samples@r[, NA:NA:-1, ], targets)\n",
        "#   })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| lst-cap: Training and evaluating a bidirectional LSTM\n",
        "inputs <- keras_input(shape = c(sequence_length, ncol_input_data))\n",
        "outputs <- inputs |>\n",
        "  layer_bidirectional(layer_lstm(units = 16)) |>\n",
        "  layer_dense(1)\n",
        "model <- keras_model(inputs, outputs)\n",
        "\n",
        "model |> compile(optimizer = \"adam\", loss = \"mse\", metrics = \"mae\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "history <- model |> fit(\n",
        "  train_dataset,\n",
        "  epochs = 10,\n",
        "  validation_data = val_dataset\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": [],
      "outputs": [],
      "source": [
        "#| fig-cap: \"Training and validation metrics for this model. Note how the validation MAE quickly plateaus and then starts creeping up, a sign of overfitting.\"\n",
        "plot(history)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R",
      "version": "4.5.2",
      "mimetype": "text/x-r-source",
      "codemirror_mode": {
        "name": "r",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
